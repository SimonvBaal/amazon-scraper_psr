---
title: "Amazon HTTP"
author: "Simon T van Baal"
date: "2024-12-09"
output: html_document
---



```{r}

packages <- 
  c("purrr",
    "renv", "stringr", 
    "usethis", 
    "httr2", "rvest", 
    "jsonlite", "dplyr", 
    "tidyr", "readr")

for (package in packages) {
  if (!require(package, character.only = TRUE)) {
    install.packages(package)
  }
  library(package, character.only = TRUE)
}

# Create a new project
# use_git_config(user.name = "Simon T van Baal", 
#                user.email = "simonvanbaal.behsci@gmail.com")
# use_git()
# use_github()




```


```{r}

# Amazon scraper

# 1. Get the Amazon Standard Identification Number (ASIN) of a product

url <- "https://www.amazon.co.uk/s?k=e-bike&low-price=225&high-price="

requester <- function(url) {
  
  # Setup the request
  req <- request(url)
  
  # To be polite, we identify ourselves to the server.
  req <- 
    req |> 
    req_headers(
    Accept = "application/json",
    `User-Agent` = "Simon van Baal, University of Leeds",
    `email` = "s.t.vanbaal@leeds.ac.uk"
  )
  
  # Get the HTML content within a tryCatch for error handling 
  
  html <- 
    tryCatch(
    
      # Attempt the GET request
      response <- req_perform(req),
      error = function(e) {
        # Handle errors (e.g., network issues, invalid URL)
        warning(sprintf("Error occurred during GET request: %s", e$message))
        NULL
    },
      warning = function(w) {
        # Handle warnings (e.g., deprecated functions)
        warning(sprintf("Warning during GET request: %s", w$message))
        invokeRestart("muffleWarning") # Muffle the warning if needed
        NULL
    }
  )
  
  # Parse the HTML content
  parsed_html <- 
    resp_body_html(html)
  
  # Return a list object with the basic information of each product
  return(parsed_html)
}

search_html_extract <- function(html) {

  # Extract the title of the product
  titles_products <- 
    html %>%
    html_elements(".a-color-base.a-text-normal") |> 
    html_text2()
  ## Better not to add prices as they are not always available, matching post-hoc
  ## is hard.
   links_products <- 
     html |> 
     html_elements("h2 > a") |> 
     html_attr("href")
  
  if (length(titles_products) == 0) {
    warning("No products found")
    return(NULL)
  }
   if (length(titles_products) != length(links_products)) {
     warning(paste0("Number of titles and prices do not match: ", 
                 length(titles_products), " titles and ", 
                 length(prices_whole_products), " prices"))
   }
  
  list_products <- 
    list(title = titles_products, 
         link = links_products)
  return(list_products)
}

# 2. Get the HTML content of the Amazon search results page

url <- "https://www.amazon.co.uk/s?k=e-bike"

html_search <- requester(url)
list_search_output <- search_html_extract(html_search)

# 3. Get the output in an easier to parse format.

dat_search_output <- 
  list_search_output |> 
  as_tibble()


```


```{r function-product-info}

product_html_extract <- function(html) {
  
  asin <- 
    html |> 
    html_elements("#productDetails_expanderTables_depthRightSections tr:nth-child(8) .prodDetAttrValue") |>
    html_text() |> 
    str_trim()
  
  details <- 
    html_product |> 
     html_elements("#productDetails_expanderTables_depthRightSections .a-section-expander-container:nth-child(1) .a-size-base , #productDetails_expanderTables_depthRightSections tr:nth-child(7) td") |>
     html_text2() 
  
  n_reviews <- 
    html |> 
    html_elements("#cm_cr_dp_d_rating_histogram .a-color-secondary") |>
    html_text2()
  
  ratings <- 
    html |> 
    html_elements(".review-rating") |>
    html_text2()
  
  review_title <- 
    html |> 
    html_elements(".a-text-bold span , #cm_cr_dp_d_rating_histogram .a-color-secondary") |>
    html_text2()
  
  review_text <- 
    html |> 
    html_elements("#cm-cr-dp-review-list .a-expander-partial-collapse-content span") |>
    html_text2()
  
  list_info <-
    list(asin = asin,
         details = details,
         n_reviews = n_reviews,
         rating = rating,
         review_title = review_title,
         review_text = review_text)
  
  return(list_info)
  
}

```



```{r}

html_product <- 
  requester(paste0("https://www.amazon.co.uk", dat_search_output$link[1]))

list_product_info <- 
  product_html_extract(html_product)



```




